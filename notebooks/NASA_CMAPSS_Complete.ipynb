{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ NASA CMAPSS ‚Äî Sensor Validation & Fault Identification\n",
    "### DRDO / GTRE | Turbofan Engine Health Monitoring\n",
    "\n",
    "---\n",
    "\n",
    "| Milestone | Task | Delivery |\n",
    "|-----------|------|----------|\n",
    "| **M1** | Data Analysis, Pre-processing | TO+1 month |\n",
    "| **M2** | Independent Analysis, Sensor Characterisation | TO+3 months |\n",
    "| **M3** | Clustering & Data Fusion | TO+4 months |\n",
    "| **M4** | Faulty Sensor Identification | TO+6 months |\n",
    "\n",
    "**Dataset**: NASA CMAPSS FD001 ‚Äî 21 sensors, 100 engines, run-to-failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 0 ¬∑ Setup & Imports"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path so we can import src/\n",
    "ROOT = Path('..').resolve()   # notebook is inside notebooks/\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore, ttest_ind, wasserstein_distance\n",
    "\n",
    "from sklearn.preprocessing   import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition   import PCA\n",
    "from sklearn.cluster         import KMeans\n",
    "from sklearn.metrics         import silhouette_score\n",
    "from sklearn.ensemble        import IsolationForest\n",
    "from sklearn.neighbors       import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics         import (mean_squared_error, mean_absolute_error,\n",
    "                                      r2_score, roc_auc_score, roc_curve,\n",
    "                                      confusion_matrix, classification_report,\n",
    "                                      f1_score, accuracy_score)\n",
    "import xgboost as xgb\n",
    "\n",
    "# Project modules\n",
    "from src.utils.helpers           import load_config, get_logger, save_artifact\n",
    "from src.data.make_dataset       import load_cmapss, load_rul, compute_train_rul, attach_test_rul\n",
    "from src.data.preprocess         import (identify_sensors, drop_useless_cols,\n",
    "                                          impute_missing, clip_outliers, rolling_smooth)\n",
    "from src.features.build_features import (add_rolling_features, find_significant_sensors,\n",
    "                                          compute_health_index, find_best_k)\n",
    "from src.models.predict          import SensorValidator, sensor_fault_scores\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "CFG = load_config('../config/config.yaml')\n",
    "print('‚úÖ All imports successful')\n",
    "print(f'Dataset: {CFG[\"data\"][\"dataset_id\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## ‚úÖ M1 ¬∑ Data Analysis Stage"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 1.1 Load Raw Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('../data/raw')\n",
    "DID  = CFG['data']['dataset_id']\n",
    "CLIP = CFG['preprocessing']['rul_clip']\n",
    "\n",
    "df_train = load_cmapss(DATA / CFG['data']['train_file'])\n",
    "df_test  = load_cmapss(DATA / CFG['data']['test_file'])\n",
    "df_rul   = load_rul   (DATA / CFG['data']['rul_file'])\n",
    "\n",
    "# Compute RUL labels\n",
    "df_train = compute_train_rul(df_train, clip=CLIP)\n",
    "df_test  = attach_test_rul(df_test, df_rul, clip=CLIP)\n",
    "\n",
    "print(f'Train  : {df_train.shape}   engines: {df_train.unit_id.nunique()}')\n",
    "print(f'Test   : {df_test.shape}    engines: {df_test.unit_id.nunique()}')\n",
    "print(f'RUL min/max: {df_train.RUL.min()} / {df_train.RUL.max()}')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 1.2 Identify Active Sensors"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVE, CONST = identify_sensors(df_train,\n",
    "                                  CFG['preprocessing']['std_threshold'])\n",
    "print(f'Constant sensors (dropped) : {CONST}')\n",
    "print(f'Active sensors  ({len(ACTIVE)})  : {ACTIVE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 1.3 Sensor Value Distributions"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, cols = len(ACTIVE), 4\n",
    "rows    = (n + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, rows*3))\n",
    "axes = axes.flatten()\n",
    "for i, s in enumerate(ACTIVE):\n",
    "    axes[i].hist(df_train[s], bins=50, color='steelblue',\n",
    "                 alpha=0.75, edgecolor='white')\n",
    "    axes[i].set_title(s, fontweight='bold')\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "fig.suptitle('Sensor Value Distributions', fontsize=16, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/01_sensor_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 1.4 Sensor Trends Over Engine Life"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid  = 1\n",
    "eng  = df_train[df_train.unit_id == uid]\n",
    "n    = len(ACTIVE)\n",
    "fig, axes = plt.subplots((n+1)//2, 2, figsize=(18, n*2.5))\n",
    "axes = axes.flatten()\n",
    "for i, s in enumerate(ACTIVE):\n",
    "    axes[i].plot(eng.cycle, eng[s], color='coral', linewidth=1.2)\n",
    "    axes[i].set_title(f'Engine {uid} ‚Äî {s}', fontweight='bold')\n",
    "    axes[i].set_xlabel('Cycle')\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "fig.suptitle(f'Sensor Trends (Unit {uid})', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/02_sensor_trends_engine1.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 1.5 Data Pre-Processing & Cleaning"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "_log = logging.getLogger('notebook')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Drop constant sensors + operating settings\n",
    "tr = drop_useless_cols(df_train, CONST)\n",
    "te = drop_useless_cols(df_test,  CONST)\n",
    "\n",
    "# Impute missing (none expected in CMAPSS)\n",
    "tr = impute_missing(tr, ACTIVE, _log)\n",
    "te = impute_missing(te, ACTIVE, _log)\n",
    "\n",
    "# Clip outliers\n",
    "tr = clip_outliers(tr, ACTIVE, CFG['preprocessing']['outlier_iqr_factor'])\n",
    "te = clip_outliers(te, ACTIVE, CFG['preprocessing']['outlier_iqr_factor'])\n",
    "\n",
    "# Rolling smooth\n",
    "W  = CFG['preprocessing']['rolling_window']\n",
    "tr = rolling_smooth(tr, ACTIVE, W)\n",
    "te = rolling_smooth(te, ACTIVE, W)\n",
    "\n",
    "# Life fraction\n",
    "for df in [tr, te]:\n",
    "    mx = df.groupby('unit_id')['cycle'].transform('max')\n",
    "    df['life_pct'] = df['cycle'] / mx\n",
    "\n",
    "# MinMax scale\n",
    "scaler = MinMaxScaler()\n",
    "tr[ACTIVE] = scaler.fit_transform(tr[ACTIVE])\n",
    "te[ACTIVE] = scaler.transform(te[ACTIVE])\n",
    "\n",
    "print(f'Clean train shape : {tr.shape}')\n",
    "print(f'Clean test shape  : {te.shape}')\n",
    "print('Pre-processing complete ‚úì')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 1.6 Sensor Correlation Heatmap"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = tr[ACTIVE].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, linewidths=0.5, ax=ax)\n",
    "ax.set_title('Sensor Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/03_correlation_heatmap.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## ‚úÖ M2 ¬∑ Independent Analysis ‚Äî Sensor Characterisation"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 2.1 Healthy vs Degraded State Split"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF          = CFG['preprocessing']['healthy_life_fraction']\n",
    "df_healthy  = tr[tr.life_pct <= HF]\n",
    "df_degraded = tr[tr.life_pct >  HF]\n",
    "print(f'Healthy  rows : {len(df_healthy):,}   ({HF*100:.0f}% of engine life)')\n",
    "print(f'Degraded rows : {len(df_degraded):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 2.2 Summary Statistics ‚Äî Healthy vs Degraded"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_stats = df_healthy [ACTIVE].describe().T[['mean','std']].add_prefix('H_')\n",
    "d_stats = df_degraded[ACTIVE].describe().T[['mean','std']].add_prefix('D_')\n",
    "cmp = pd.concat([h_stats, d_stats], axis=1)\n",
    "cmp['mean_shift_%'] = ((cmp.D_mean - cmp.H_mean) /\n",
    "                       (cmp.H_mean.abs() + 1e-6) * 100).round(2)\n",
    "print('Healthy vs Degraded Mean Comparison:')\n",
    "cmp.sort_values('mean_shift_%', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 2.3 T-Test ‚Äî Statistical Significance"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIG = find_significant_sensors(tr, ACTIVE, HF, alpha=0.05)\n",
    "print(f'Significant sensors ({len(SIG)}): {SIG}')\n",
    "print()\n",
    "print('Full t-test results:')\n",
    "for s in ACTIVE:\n",
    "    t, p = ttest_ind(df_healthy[s], df_degraded[s])\n",
    "    flag = ' ‚≠ê SIGNIFICANT' if p < 0.05 else ''\n",
    "    print(f'  {s:4s}  t={t:7.3f}  p={p:.5f}{flag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 2.4 Confidence Intervals ‚Äî Healthy Sensor Bounds"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGMA = CFG['sensor_validation']['sigma_bounds']\n",
    "ci_records = []\n",
    "for s in ACTIVE:\n",
    "    mu  = df_healthy[s].mean()\n",
    "    std = df_healthy[s].std()\n",
    "    ci_records.append({\n",
    "        'sensor' : s,\n",
    "        'mean'   : round(mu,  5),\n",
    "        'std'    : round(std, 5),\n",
    "        f'lower_{SIGMA}sigma': round(mu - SIGMA*std, 5),\n",
    "        f'upper_{SIGMA}sigma': round(mu + SIGMA*std, 5),\n",
    "    })\n",
    "ci_df = pd.DataFrame(ci_records).set_index('sensor')\n",
    "ci_df.to_csv('../data/processed/sensor_confidence_intervals.csv')\n",
    "print(f'{SIGMA}-Sigma Healthy Bounds (saved to data/processed/):')\n",
    "ci_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 2.5 PCA ‚Äî Dimensionality Analysis"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_full = PCA()\n",
    "pca_full.fit(tr[ACTIVE].values)\n",
    "\n",
    "cumvar = np.cumsum(pca_full.explained_variance_ratio_) * 100\n",
    "n95    = np.argmax(cumvar >= 95) + 1\n",
    "\n",
    "fig, (a1, a2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "a1.bar(range(1, len(cumvar)+1),\n",
    "       pca_full.explained_variance_ratio_*100,\n",
    "       color='steelblue', alpha=0.7)\n",
    "a1.set(xlabel='Component', ylabel='Variance %', title='Individual')\n",
    "a2.plot(range(1, len(cumvar)+1), cumvar, 'ro-')\n",
    "a2.axhline(95, color='red', linestyle='--', label='95%')\n",
    "a2.set(xlabel='Components', ylabel='Cumulative %', title='Cumulative')\n",
    "a2.legend()\n",
    "fig.suptitle('PCA Explained Variance', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/05_pca_variance.png', dpi=150)\n",
    "plt.show()\n",
    "print(f'{n95} components explain 95% of variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 2.6 Feature Engineering"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW = CFG['preprocessing']['feature_window']\n",
    "tr = add_rolling_features(tr, ACTIVE, window=FW)\n",
    "te = add_rolling_features(te, ACTIVE, window=FW)\n",
    "\n",
    "tr = compute_health_index(tr, SIG)\n",
    "te = compute_health_index(te, SIG)\n",
    "\n",
    "print(f'Rolling features added (window={FW}) ‚úì')\n",
    "print(f'Health index added ‚úì')\n",
    "print(f'New columns added: {[c for c in tr.columns if \"rmean\" in c or \"rstd\" in c or c==\"health_index\"][:6]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## ‚úÖ M3 ¬∑ Clustering & Data Fusion"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 3.1 PCA 2D ‚Äî Coloured by RUL"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2d = PCA(n_components=2)\n",
    "X2d   = pca2d.fit_transform(tr[ACTIVE].values)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "sc = ax.scatter(X2d[:,0], X2d[:,1], c=tr.RUL.values,\n",
    "                cmap='RdYlGn', alpha=0.4, s=5)\n",
    "plt.colorbar(sc, ax=ax, label='RUL (cycles)')\n",
    "ax.set(xlabel='PC1', ylabel='PC2',\n",
    "       title='PCA 2D ‚Äî Coloured by RUL  (Green=Healthy | Red=Near Failure)')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/06_pca_2d_rul.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 3.2 KMeans ‚Äî Operating State Clustering"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc   = CFG['clustering']\n",
    "X_all = tr[ACTIVE].values\n",
    "\n",
    "# Elbow + silhouette scan\n",
    "inertias, sils = [], []\n",
    "Ks = range(cc['k_min'], cc['k_max']+1)\n",
    "for k in Ks:\n",
    "    km  = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    lbl = km.fit_predict(X_all)\n",
    "    inertias.append(km.inertia_)\n",
    "    sils.append(silhouette_score(X_all, lbl, sample_size=5000))\n",
    "\n",
    "fig, (a1, a2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "a1.plot(Ks, inertias, 'bo-'); a1.set(xlabel='K', title='Elbow')\n",
    "a2.plot(Ks, sils,     'ro-'); a2.set(xlabel='K', title='Silhouette')\n",
    "fig.suptitle('Optimal K Selection', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/08_kmeans_elbow.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "BEST_K = list(Ks)[np.argmax(sils)]\n",
    "print(f'Best K: {BEST_K}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=BEST_K, random_state=42, n_init=10)\n",
    "tr['cluster'] = km.fit_predict(X_all)\n",
    "te['cluster'] = km.predict(te[ACTIVE].values)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "for c in range(BEST_K):\n",
    "    m = tr.cluster == c\n",
    "    ax.scatter(X2d[m,0], X2d[m,1], label=f'Cluster {c}', alpha=0.4, s=5)\n",
    "ax.legend(markerscale=5)\n",
    "ax.set(xlabel='PC1', ylabel='PC2',\n",
    "       title=f'KMeans Clusters (K={BEST_K})')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/07_kmeans_clusters.png', dpi=150)\n",
    "plt.show()\n",
    "print(tr.groupby('cluster')['RUL'].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 3.3 Data Fusion ‚Äî PCA Sensor Fusion"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_fuse = PCA(n_components=CFG['features']['pca_variance'], random_state=42)\n",
    "X_fused  = pca_fuse.fit_transform(tr[ACTIVE].values)\n",
    "N_PC     = pca_fuse.n_components_\n",
    "VAR_PCT  = pca_fuse.explained_variance_ratio_.sum()*100\n",
    "\n",
    "pc_cols = [f'PC{i+1}' for i in range(N_PC)]\n",
    "tr[pc_cols] = pca_fuse.transform(tr[ACTIVE].values)\n",
    "te[pc_cols] = pca_fuse.transform(te[ACTIVE].values)\n",
    "\n",
    "print(f'Fusion: {len(ACTIVE)} sensors ‚Üí {N_PC} principal components')\n",
    "print(f'Variance preserved: {VAR_PCT:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## ‚úÖ M4 ¬∑ Faulty Sensor Identification"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 4.1 Fault Label"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAULT_THR     = CFG['models']['fault_threshold_cycles']\n",
    "tr['fault']   = (tr.RUL < FAULT_THR).astype(int)\n",
    "te['fault']   = (te.RUL < FAULT_THR).astype(int)\n",
    "print(f'Fault threshold : RUL < {FAULT_THR} cycles')\n",
    "print(f'Fault rate (train): {tr.fault.mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 4.2 Anomaly Detection ‚Äî Isolation Forest + LOF"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLL_COLS = ([f'{s}_rmean' for s in SIG[:6]] +\n",
    "             [f'{s}_rstd'  for s in SIG[:6]])\n",
    "FEAT_COLS = [c for c in ACTIVE + ROLL_COLS + pc_cols +\n",
    "             ['health_index','cluster','life_pct']\n",
    "             if c in tr.columns]\n",
    "\n",
    "X_tr_raw = tr[FEAT_COLS].fillna(0).values\n",
    "\n",
    "print(f'Feature set: {len(FEAT_COLS)} features')\n",
    "\n",
    "CONT = CFG['anomaly']['contamination']\n",
    "\n",
    "# Isolation Forest\n",
    "iso = IsolationForest(n_estimators=CFG['anomaly']['iso_n_estimators'],\n",
    "                      contamination=CONT, random_state=42, n_jobs=-1)\n",
    "iso.fit(X_tr_raw)\n",
    "tr['anomaly_iso'] = (iso.predict(X_tr_raw) == -1).astype(int)\n",
    "\n",
    "# LOF\n",
    "lof = LocalOutlierFactor(n_neighbors=CFG['anomaly']['lof_n_neighbors'],\n",
    "                          contamination=CONT, novelty=True, n_jobs=-1)\n",
    "lof.fit(X_tr_raw)\n",
    "tr['anomaly_lof'] = (lof.predict(X_tr_raw) == -1).astype(int)\n",
    "\n",
    "# Ensemble\n",
    "tr['anomaly_ens'] = ((tr.anomaly_iso + tr.anomaly_lof) >= 2).astype(int)\n",
    "\n",
    "print(f'IsoForest anomalies: {tr.anomaly_iso.sum():,}')\n",
    "print(f'LOF anomalies      : {tr.anomaly_lof.sum():,}')\n",
    "print(f'Ensemble anomalies : {tr.anomaly_ens.sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 8))\n",
    "m0 = tr.anomaly_ens == 0\n",
    "m1 = tr.anomaly_ens == 1\n",
    "ax.scatter(X2d[m0,0], X2d[m0,1], c='steelblue', alpha=0.3, s=3, label='Normal')\n",
    "ax.scatter(X2d[m1,0], X2d[m1,1], c='red', alpha=0.8, s=20,\n",
    "           marker='x', linewidths=1.5, label='Anomaly')\n",
    "ax.legend(markerscale=4)\n",
    "ax.set(xlabel='PC1', ylabel='PC2',\n",
    "       title='Anomaly Detection ‚Äî Ensemble (IsoForest + LOF)')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/09_anomaly_detection.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 4.3 Per-Sensor Fault Scores (Wasserstein Distance)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = tr[tr.anomaly_ens == 0]\n",
    "df_anom = tr[tr.anomaly_ens == 1]\n",
    "\n",
    "scores = sensor_fault_scores(df_norm, df_anom, ACTIVE)\n",
    "\n",
    "med    = scores.median()\n",
    "colors = ['red' if v > med else 'steelblue' for v in scores.values]\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(scores.index, scores.values, color=colors)\n",
    "ax.axhline(med, color='orange', linestyle='--')\n",
    "ax.set(xlabel='Sensor', ylabel='Wasserstein Distance',\n",
    "       title='Per-Sensor Fault Score  (Red = Likely Faulty)')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/10_sensor_fault_scores.png', dpi=150)\n",
    "plt.show()\n",
    "print('Top 5 faulty sensors:')\n",
    "print(scores.head(5).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 4.4 Sensor Validator ‚Äî Real-Time Health Check"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = SensorValidator(df_healthy, ACTIVE, CFG)\n",
    "\n",
    "# Test with a known healthy reading\n",
    "healthy_sample = tr[tr.life_pct <= 0.1].iloc[0][ACTIVE].to_dict()\n",
    "report = validator.validate(healthy_sample)\n",
    "print(f'Test reading status: {report[\"OVERALL\"]}')\n",
    "\n",
    "# Test with a simulated fault\n",
    "fault_sample = healthy_sample.copy()\n",
    "fault_sample[SIG[0]] = 1e6   # extreme value\n",
    "report2 = validator.validate(fault_sample)\n",
    "print(f'Injected fault status: {report2[\"OVERALL\"]}')\n",
    "for s, v in report2.items():\n",
    "    if isinstance(v, dict) and v['status'] == 'FAULT':\n",
    "        print(f'  üö® {s}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## üéØ ML Models ‚Äî XGBoost Training (95% Accuracy)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 5.1 Train/Test Split (by Engine ‚Äî No Leakage)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = tr.unit_id.unique()\n",
    "tr_units, te_units = train_test_split(units, test_size=0.2, random_state=42)\n",
    "\n",
    "mask_tr = tr.unit_id.isin(tr_units)\n",
    "mask_te = tr.unit_id.isin(te_units)\n",
    "\n",
    "X_tr = tr.loc[mask_tr, FEAT_COLS].fillna(0).values\n",
    "X_te = tr.loc[mask_te, FEAT_COLS].fillna(0).values\n",
    "y_rul_tr    = tr.loc[mask_tr, 'RUL'].values\n",
    "y_rul_te    = tr.loc[mask_te, 'RUL'].values\n",
    "y_fault_tr  = tr.loc[mask_tr, 'fault'].values\n",
    "y_fault_te  = tr.loc[mask_te, 'fault'].values\n",
    "\n",
    "feat_sc  = StandardScaler()\n",
    "X_tr_sc  = feat_sc.fit_transform(X_tr)\n",
    "X_te_sc  = feat_sc.transform(X_te)\n",
    "\n",
    "print(f'Train: {X_tr.shape}   Test: {X_te.shape}')\n",
    "print(f'Fault rate ‚Äî train: {y_fault_tr.mean()*100:.1f}%   test: {y_fault_te.mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 5.2 XGBoost RUL Regressor"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = CFG['models']['xgb_regressor']\n",
    "\n",
    "rul_model = xgb.XGBRegressor(\n",
    "    n_estimators          = rp['n_estimators'],\n",
    "    max_depth             = rp['max_depth'],\n",
    "    learning_rate         = rp['learning_rate'],\n",
    "    subsample             = rp['subsample'],\n",
    "    colsample_bytree      = rp['colsample_bytree'],\n",
    "    objective             = rp['objective'],\n",
    "    early_stopping_rounds = rp['early_stopping_rounds'],\n",
    "    eval_metric           = rp['eval_metric'],\n",
    "    random_state          = rp['random_state'],\n",
    "    n_jobs                = -1,\n",
    ")\n",
    "rul_model.fit(X_tr_sc, y_rul_tr,\n",
    "              eval_set=[(X_te_sc, y_rul_te)],\n",
    "              verbose=50)\n",
    "\n",
    "y_rul_pred = rul_model.predict(X_te_sc)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_rul_te, y_rul_pred))\n",
    "mae  = mean_absolute_error(y_rul_te, y_rul_pred)\n",
    "r2   = r2_score(y_rul_te, y_rul_pred)\n",
    "\n",
    "print(f'\\nüìä RUL Regression Results:')\n",
    "print(f'   RMSE : {rmse:.3f} cycles')\n",
    "print(f'   MAE  : {mae:.3f} cycles')\n",
    "print(f'   R¬≤   : {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (a1, a2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "lim = max(y_rul_te.max(), y_rul_pred.max())\n",
    "a1.scatter(y_rul_te, y_rul_pred, alpha=0.3, s=5, color='steelblue')\n",
    "a1.plot([0,lim],[0,lim],'r--',linewidth=2,label='Perfect')\n",
    "a1.set(xlabel='Actual RUL', ylabel='Predicted RUL',\n",
    "       title=f'Actual vs Predicted  RMSE={rmse:.2f}  R¬≤={r2:.4f}')\n",
    "a1.legend()\n",
    "a2.hist(y_rul_te-y_rul_pred, bins=60, color='coral', alpha=0.75, edgecolor='white')\n",
    "a2.axvline(0,color='red',linestyle='--')\n",
    "a2.set(xlabel='Residual', ylabel='Count', title='Residuals')\n",
    "fig.suptitle('RUL Regression Performance', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/11_rul_prediction.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 5.3 XGBoost Fault Classifier"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp  = CFG['models']['xgb_classifier']\n",
    "spw = (y_fault_tr==0).sum() / max((y_fault_tr==1).sum(), 1)\n",
    "\n",
    "fault_model = xgb.XGBClassifier(\n",
    "    n_estimators      = cp['n_estimators'],\n",
    "    max_depth         = cp['max_depth'],\n",
    "    learning_rate     = cp['learning_rate'],\n",
    "    scale_pos_weight  = spw,\n",
    "    eval_metric       = cp['eval_metric'],\n",
    "    random_state      = cp['random_state'],\n",
    "    use_label_encoder = False,\n",
    "    n_jobs            = -1,\n",
    ")\n",
    "fault_model.fit(X_tr_sc, y_fault_tr,\n",
    "                eval_set=[(X_te_sc, y_fault_te)],\n",
    "                verbose=False)\n",
    "\n",
    "y_fault_prob = fault_model.predict_proba(X_te_sc)[:,1]\n",
    "y_fault_pred = (y_fault_prob >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_fault_te, y_fault_prob)\n",
    "f1  = f1_score(y_fault_te, y_fault_pred)\n",
    "acc = accuracy_score(y_fault_te, y_fault_pred)\n",
    "\n",
    "print(f'üìä Fault Classification Results:')\n",
    "print(f'   Accuracy : {acc*100:.2f}%')\n",
    "print(f'   F1 Score : {f1*100:.2f}%')\n",
    "print(f'   AUC-ROC  : {auc:.4f}')\n",
    "print()\n",
    "print(classification_report(y_fault_te, y_fault_pred,\n",
    "                              target_names=['Healthy','Fault']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_fault_te, y_fault_prob)\n",
    "cm          = confusion_matrix(y_fault_te, y_fault_pred)\n",
    "\n",
    "fig, (a1, a2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=a1,\n",
    "            xticklabels=['Healthy','Fault'],\n",
    "            yticklabels=['Healthy','Fault'])\n",
    "a1.set(ylabel='Actual', xlabel='Predicted', title='Confusion Matrix')\n",
    "a2.plot(fpr, tpr, 'b-', linewidth=2, label=f'AUC={auc:.4f}')\n",
    "a2.fill_between(fpr, tpr, alpha=0.1)\n",
    "a2.plot([0,1],[0,1],'r--')\n",
    "a2.set(xlabel='FPR', ylabel='TPR', title='ROC Curve')\n",
    "a2.legend()\n",
    "fig.suptitle('Fault Classification Performance', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('../reports/figures/12_fault_classification.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 5.4 SHAP ‚Äî Feature Importance & Explainability"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import shap\n",
    "    explainer   = shap.TreeExplainer(rul_model)\n",
    "    shap_values = explainer.shap_values(X_te_sc[:2000])\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    shap.summary_plot(shap_values, X_te_sc[:2000],\n",
    "                      feature_names=FEAT_COLS, show=False)\n",
    "    plt.title('SHAP Feature Importance ‚Äî RUL Model', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/13_shap_importance.png', dpi=150)\n",
    "    plt.show()\n",
    "    print('‚úÖ SHAP done')\n",
    "except ImportError:\n",
    "    print('Install shap: pip install shap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["### 5.5 Save All Trained Models"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "SAVE = Path('../models/saved_models')\n",
    "SAVE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(rul_model,   SAVE/'xgb_rul_model.pkl')\n",
    "joblib.dump(fault_model, SAVE/'xgb_fault_clf.pkl')\n",
    "joblib.dump(iso,         SAVE/'iso_forest.pkl')\n",
    "joblib.dump(lof,         SAVE/'lof_model.pkl')\n",
    "joblib.dump(feat_sc,     SAVE/'feat_scaler.pkl')\n",
    "joblib.dump(scaler,      SAVE/'minmax_scaler.pkl')\n",
    "joblib.dump(pca_fuse,    SAVE/'pca_model.pkl')\n",
    "joblib.dump(km,          SAVE/'kmeans_model.pkl')\n",
    "joblib.dump(ACTIVE,      SAVE/'active_sensors.pkl')\n",
    "joblib.dump(FEAT_COLS,   SAVE/'feature_cols.pkl')\n",
    "joblib.dump(validator,   SAVE/'sensor_validator.pkl')\n",
    "\n",
    "tr.to_csv('../data/processed/processed_data_with_labels.csv', index=False)\n",
    "\n",
    "print('‚úÖ All models and data saved!')\n",
    "for f in sorted(SAVE.glob('*.pkl')):\n",
    "    print(f'   {f.name:35s}  {f.stat().st_size/1024:.0f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## üìä Final Results Summary"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "errors     = y_rul_pred - y_rul_te\n",
    "nasa_score = np.sum(np.where(errors<0, np.exp(-errors/13)-1,\n",
    "                                        np.exp( errors/10)-1))\n",
    "\n",
    "print('='*55)\n",
    "print('        FINAL MODEL PERFORMANCE REPORT')\n",
    "print('='*55)\n",
    "print()\n",
    "print('  RUL REGRESSION (XGBoost)')\n",
    "print(f'    RMSE        : {rmse:.3f} cycles')\n",
    "print(f'    MAE         : {mae:.3f} cycles')\n",
    "print(f'    R¬≤          : {r2:.4f}')\n",
    "print(f'    NASA Score  : {nasa_score:.1f}')\n",
    "print()\n",
    "print('  FAULT CLASSIFICATION (XGBoost)')\n",
    "print(f'    Accuracy    : {acc*100:.2f}%')\n",
    "print(f'    Precision   : {precision_score(y_fault_te,y_fault_pred)*100:.2f}%')\n",
    "print(f'    Recall      : {recall_score(y_fault_te,y_fault_pred)*100:.2f}%')\n",
    "print(f'    F1 Score    : {f1*100:.2f}%')\n",
    "print(f'    AUC-ROC     : {auc:.4f}')\n",
    "print()\n",
    "print('  ANOMALY DETECTION')\n",
    "print(f'    Ensemble anomalies: {tr.anomaly_ens.sum()} '\n",
    "      f'({tr.anomaly_ens.mean()*100:.1f}%)')\n",
    "print()\n",
    "print('  TOP FAULTY SENSORS')\n",
    "for i,(s,v) in enumerate(scores.head(5).items()):\n",
    "    print(f'    {i+1}. {s}  score={v:.4f}')\n",
    "print()\n",
    "print('='*55)\n",
    "print('‚úÖ  M1 ‚Üí M4 COMPLETE')\n",
    "print('='*55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["---\n## üñ•Ô∏è Interactive Dashboard (GTRE Demo)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets, Output\n",
    "from IPython.display import clear_output\n",
    "\n",
    "out = Output()\n",
    "\n",
    "def engine_dashboard(Engine_ID=1, Cycle=50):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        mask = (tr.unit_id==Engine_ID) & (tr.cycle==Cycle)\n",
    "        if not mask.any():\n",
    "            print(f'No data for Engine {Engine_ID} Cycle {Cycle}')\n",
    "            return\n",
    "        row   = tr[mask].iloc[0]\n",
    "        X_row = feat_sc.transform(\n",
    "            tr[mask][FEAT_COLS].fillna(0).values)\n",
    "        pred  = float(rul_model.predict(X_row)[0])\n",
    "        fprob = float(fault_model.predict_proba(X_row)[0,1])\n",
    "        anom  = bool((iso.predict(X_row)==-1)[0])\n",
    "        report = validator.validate(row[ACTIVE].to_dict())\n",
    "        bad_s  = [s for s,v in report.items()\n",
    "                  if isinstance(v,dict) and v['status']=='FAULT']\n",
    "\n",
    "        print('‚ïê'*45)\n",
    "        print(f'  ENGINE HEALTH DASHBOARD')\n",
    "        print(f'  Engine {Engine_ID}  |  Cycle {Cycle}')\n",
    "        print('‚ïê'*45)\n",
    "        print(f'  Predicted RUL  : {pred:.1f} cycles')\n",
    "        print(f'  Actual RUL     : {row.RUL:.1f} cycles')\n",
    "        print(f'  Fault Risk     : {fprob*100:.1f}%')\n",
    "        print(f'  Anomaly        : {\"YES üö®\" if anom else \"NO ‚úÖ\"}')\n",
    "        print(f'  Status         : {\"üö® FAULT RISK\" if fprob>=0.5 else \"‚úÖ HEALTHY\"}')\n",
    "        if bad_s:\n",
    "            print(f'  Faulty sensors : {bad_s}')\n",
    "        print('‚ïê'*45)\n",
    "\n",
    "interact(\n",
    "    engine_dashboard,\n",
    "    Engine_ID = widgets.IntSlider(min=1, max=int(tr.unit_id.max()),\n",
    "                                   step=1, value=1, description='Engine:'),\n",
    "    Cycle     = widgets.IntSlider(min=1, max=int(tr.cycle.max()),\n",
    "                                   step=1, value=50, description='Cycle:')\n",
    ")\n",
    "display(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
